{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "585f2a0897f04fdf86e7a80b7957c18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5d5d05f114b447318246e30ee3f4b32f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d1e4c6b9d0a04a83916f80a02bada0f2",
              "IPY_MODEL_fbc43bb6d30d41edbcf51cf4d1fc8686"
            ]
          }
        },
        "5d5d05f114b447318246e30ee3f4b32f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1e4c6b9d0a04a83916f80a02bada0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2bf6690a24e44fdd818f7974d9d8ef65",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5c1590400884971a7e2fa3b36067ddf"
          }
        },
        "fbc43bb6d30d41edbcf51cf4d1fc8686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c33404ac00f4bdf9ac70c08cfc65cdf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:44&lt;00:00, 1.05MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fa9c01036fb4dc291c4401df64b1d98"
          }
        },
        "2bf6690a24e44fdd818f7974d9d8ef65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5c1590400884971a7e2fa3b36067ddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c33404ac00f4bdf9ac70c08cfc65cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fa9c01036fb4dc291c4401df64b1d98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD2k1SOSFASV"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXaEj3e6M9tc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c82166c-4462-4c3b-e8db-9329eeb20ecf"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7MW5XdtWgsn",
        "outputId": "e6f5c7c0-2436-4e9b-a245-6c5c3b678fba"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Apr 24 10:36:48 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DA3PXOfWzq8"
      },
      "source": [
        "my_tensor=torch.tensor(np.random.rand(3,4))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7gOyMwIXZ1w",
        "outputId": "a615cdc1-3ced-4149-cd78-75392797b673"
      },
      "source": [
        "my_tensor.to(\"cuda\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3391, 0.3842, 0.5118, 0.2598],\n",
              "        [0.4201, 0.8922, 0.1455, 0.9060],\n",
              "        [0.2281, 0.6602, 0.0165, 0.5521]], device='cuda:0',\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZWRgRtEXpg0",
        "outputId": "06aef6c3-3df2-422b-95f6-14b11a3b0177"
      },
      "source": [
        "my_tensor*my_tensor"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.1501e-01, 1.4762e-01, 2.6194e-01, 6.7490e-02],\n",
              "        [1.7645e-01, 7.9606e-01, 2.1181e-02, 8.2082e-01],\n",
              "        [5.2052e-02, 4.3585e-01, 2.7171e-04, 3.0478e-01]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jYhgMA0X4aG",
        "outputId": "898c8026-011a-4749-a0b3-e0c65fa77401"
      },
      "source": [
        "my_tensor.matmul(my_tensor.T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.2324, 1.3741, 1.1149],\n",
              "        [1.3741, 2.1569, 1.4128],\n",
              "        [1.1149, 1.4128, 1.4151]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2xu-Hv5X-EM",
        "outputId": "8b883193-c379-40f4-fb39-4f727048c710"
      },
      "source": [
        "my_tensor @ my_tensor.T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.2324, 1.3741, 1.1149],\n",
              "        [1.3741, 2.1569, 1.4128],\n",
              "        [1.1149, 1.4128, 1.4151]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk5s-adlYD4F",
        "outputId": "227c42b1-c88a-4412-a7e2-b0e961a0c025"
      },
      "source": [
        "torch.nn.functional.softmax(my_tensor, dim=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3094, 0.4258, 0.2526, 0.2823],\n",
              "        [0.3535, 0.2752, 0.3471, 0.5023],\n",
              "        [0.3370, 0.2990, 0.4003, 0.2154]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1eBdATVYYqp",
        "outputId": "752b7b22-2c35-4fde-8fba-511ae2bb47c8"
      },
      "source": [
        "torch.rand(1,2,2,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.7306, 0.7314, 0.3509],\n",
              "          [0.6193, 0.3747, 0.9781]],\n",
              "\n",
              "         [[0.7917, 0.9425, 0.4403],\n",
              "          [0.5069, 0.2976, 0.1779]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZCSZPPfYnJG",
        "outputId": "83cc153d-db4f-4f19-bbac-afdb7328a56d"
      },
      "source": [
        "my_tensor.clip(0.2,0.8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5633, 0.2000, 0.8000, 0.2650],\n",
              "        [0.5392, 0.7844, 0.3762, 0.7459],\n",
              "        [0.2000, 0.6215, 0.8000, 0.7315]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-dMFgSYYtL9",
        "outputId": "03a80792-ee2d-4164-8138-453b71438ec3"
      },
      "source": [
        "torch.ones(1,2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZwYz1NtZnm9",
        "outputId": "29aa6184-cd59-4ab3-974d-ca1e8b17f749"
      },
      "source": [
        "torch.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.device"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HebQ0OotZrtw",
        "outputId": "b5b3e98c-5da5-4ac5-ca28-cbb2bf1ab656"
      },
      "source": [
        "torch.get_num_threads()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jdNkZbDasBz"
      },
      "source": [
        "a = torch.tensor([5.], requires_grad=True)\n",
        "b = torch.tensor([6.], requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrvXzFiNbZd_",
        "outputId": "00d7bc01-d2a6-4a22-90c2-ee34cfdfdd4b"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW96-USGbaIM"
      },
      "source": [
        "y = a**3 -b**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewc3u0smbceO"
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcXUVKPcbdhV",
        "outputId": "db0a3b32-f70c-4f1c-e1fb-8c7716e4c314"
      },
      "source": [
        "print(a.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([75.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcbv680mbzPu",
        "outputId": "2fa867cc-30b6-4cce-c443-c0d93cd3957e"
      },
      "source": [
        "W = torch.rand(10,1, requires_grad=True)\n",
        "W"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8391],\n",
              "        [0.8638],\n",
              "        [0.3635],\n",
              "        [0.4724],\n",
              "        [0.3941],\n",
              "        [0.5406],\n",
              "        [0.8557],\n",
              "        [0.6668],\n",
              "        [0.5588],\n",
              "        [0.3464]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67J6gVggcGnf"
      },
      "source": [
        "x=torch.rand(1,10)\n",
        "b=torch.rand(1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8yyfVDrcQ3C",
        "outputId": "adcc86cc-9009-4b48-8910-1f25d992407c"
      },
      "source": [
        "op = torch.matmul(x,W) + b\n",
        "op.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77DsFVUAcdbk",
        "outputId": "890adca6-c9fe-445b-b524-4115c89ea876"
      },
      "source": [
        "loss = 1 - op\n",
        "op"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.7148]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d80DjJ2Och2T"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W-b4Lwzdwdx",
        "outputId": "9ec5b6d4-5f0b-443f-be17-e6df17723268"
      },
      "source": [
        "W.grad.data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9469],\n",
              "        [-0.2981],\n",
              "        [-0.8220],\n",
              "        [-0.7769],\n",
              "        [-0.6005],\n",
              "        [-0.4380],\n",
              "        [-0.2791],\n",
              "        [-0.8605],\n",
              "        [-0.4555],\n",
              "        [-0.2733]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "585f2a0897f04fdf86e7a80b7957c18e",
            "5d5d05f114b447318246e30ee3f4b32f",
            "d1e4c6b9d0a04a83916f80a02bada0f2",
            "fbc43bb6d30d41edbcf51cf4d1fc8686",
            "2bf6690a24e44fdd818f7974d9d8ef65",
            "f5c1590400884971a7e2fa3b36067ddf",
            "0c33404ac00f4bdf9ac70c08cfc65cdf",
            "5fa9c01036fb4dc291c4401df64b1d98"
          ]
        },
        "id": "UNTvmqtTdzRD",
        "outputId": "91347872-1c07-475f-a820-5a193d30ee35"
      },
      "source": [
        "import torch, torchvision\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "data = torch.rand(1,3,64,64)\n",
        "labels = torch.rand(1, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "585f2a0897f04fdf86e7a80b7957c18e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Lr0BHnez7I"
      },
      "source": [
        "prediction = model(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUlyFVUke4aS"
      },
      "source": [
        "loss = (prediction - labels).sum()\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrwzsg_afCCI"
      },
      "source": [
        "optim = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iANTIO5LfQv3"
      },
      "source": [
        "optim.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9DBhhsgOVjH"
      },
      "source": [
        "test1=torch.rand(1,3,8,8)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3vH4kAmOZgS"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGNee05JO9Sr",
        "outputId": "ff4b587d-169c-44ad-c8e5-38f1c8c129fc"
      },
      "source": [
        "conv_layer = Conv2d( 3, 8, 5, )\n",
        "output = conv_layer(test1)\n",
        "output.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rt70bgrQwSH"
      },
      "source": [
        "from torch.nn import Conv2d, functional as F, Linear, MaxPool2d, Module, Sequential\n",
        "class SimpleNet(Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(SimpleNet, self).__init__()\n",
        "    \n",
        "    self.cnn_layers = Sequential(\n",
        "        Conv2d(1, 4,  kernel_size=3,  stride=1, padding=1),\n",
        "        BatchNorm2d(4),\n",
        "        ReLU(inplace=True),\n",
        "        MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
        "        BatchNorm2d(4),\n",
        "        ReLU(inplace=True),\n",
        "        MaxPool2d(kernel_size=2, stride=2),\n",
        "    )\n",
        "\n",
        "    self.linear_layers = Sequential(\n",
        "        Linear(4 * 7 * 7, 10)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    \n",
        "\n",
        "    x = self.cnn_layers(x)\n",
        "    x = x.view(x.size(0),-1)\n",
        "    x = self.linear_layers(x)\n",
        "    return x"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqHmT5-FSFCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6fe4e3-b7d2-412d-fe13-37216938b26f"
      },
      "source": [
        "model = SimpleNet()\n",
        "optimizer = Adam(model.parameters(), lr=0.07)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "  model = model.cuda()\n",
        "  criterion = criterion.cuda()\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SimpleNet(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=196, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3lHtLVzaiGs",
        "outputId": "823ea7b6-35ee-454f-d297-2a69994ff13d"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SimpleNet(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=196, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5gSh0LKauuD"
      },
      "source": [
        "import tensorflow as tf\n",
        "(x__train, y__train), (x__test, y__test)  = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MurXk_QZf2kg",
        "outputId": "fa5a57eb-b160-42d3-8cb4-31e77c098770"
      },
      "source": [
        "x__train = x__train/255\n",
        "x__test = x__test/255\n",
        "x__test.dtype"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "67PKIQL0pvIP",
        "outputId": "2de842cb-28c4-4cbf-d385-abb6e2323bcc"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "torch.cuda.memory_summary(device='cuda')"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 15           |        cudaMalloc retries: 15        |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   13034 MB |   13685 MB |  569894 MB |  556859 MB |\\n|       from large pool |   13020 MB |   13670 MB |  569601 MB |  556581 MB |\\n|       from small pool |      14 MB |      16 MB |     292 MB |     278 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   13034 MB |   13685 MB |  569894 MB |  556859 MB |\\n|       from large pool |   13020 MB |   13670 MB |  569601 MB |  556581 MB |\\n|       from small pool |      14 MB |      16 MB |     292 MB |     278 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   13878 MB |   13934 MB |   18640 MB |    4762 MB |\\n|       from large pool |   13860 MB |   13918 MB |   18616 MB |    4756 MB |\\n|       from small pool |      18 MB |      18 MB |      24 MB |       6 MB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |     843 MB |    7300 MB |  524275 MB |  523432 MB |\\n|       from large pool |     839 MB |    7291 MB |  523946 MB |  523107 MB |\\n|       from small pool |       3 MB |      10 MB |     328 MB |     325 MB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     417    |     646    |   12736    |   12319    |\\n|       from large pool |     150    |     270    |    4118    |    3968    |\\n|       from small pool |     267    |     376    |    8618    |    8351    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     417    |     646    |   12736    |   12319    |\\n|       from large pool |     150    |     270    |    4118    |    3968    |\\n|       from small pool |     267    |     376    |    8618    |    8351    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      22    |      22    |      32    |      10    |\\n|       from large pool |      13    |      15    |      20    |       7    |\\n|       from small pool |       9    |       9    |      12    |       3    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      32    |      63    |    7821    |    7789    |\\n|       from large pool |      17    |      23    |    1720    |    1703    |\\n|       from small pool |      15    |      43    |    6101    |    6086    |\\n|===========================================================================|\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn461VPKcxan",
        "outputId": "a6a8bffc-7263-42c8-fbba-0acf40d322f8"
      },
      "source": [
        "x_train_np  = x__train.reshape(60000, 1, 28, 28)\n",
        "x_train_tensor  = torch.as_tensor(x_train_np, dtype=torch.float32)\n",
        "x_test_np = x__test.reshape(10000, 1, 28, 28)\n",
        "x_test_tensor = torch.as_tensor(x_test_np, dtype=torch.float32)\n",
        "x_test_tensor.shape"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3qKh6zwxcjf",
        "outputId": "392e6bc8-85c6-4ba1-8e0f-d8e8b115c861"
      },
      "source": [
        "train_loader  = torch.utils.data.DataLoader(x_train_tensor, batch_size=8)\n",
        "for data in train_loader:\n",
        "  print(data.shape)\n",
        "  break"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6F0mJH_gU8Z",
        "outputId": "300e0458-278f-4ca9-9e4b-9cbb7b860a19"
      },
      "source": [
        "y_train_np  = y__train.astype(int)\n",
        "y_train_tensor  = torch.from_numpy(y_train_np)\n",
        "y_test_np = y__test.astype(int)\n",
        "y_test_tensor = torch.from_numpy(y_test_np)\n",
        "y_test_tensor.dtype"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNampronbEcH"
      },
      "source": [
        "n_epoch = 25\n",
        "train_losses  = []\n",
        "test_losses =  []\n",
        "\n",
        "def train(epoch):\n",
        "\n",
        "  model.train()\n",
        "  tr_loss = 0\n",
        "\n",
        "  x_train,  y_train = torch.tensor(x_train_tensor, requires_grad=True),  torch.tensor(y_train_tensor, dtype=torch.long)\n",
        "  x_test, y_test  = torch.tensor(x_test_tensor, requires_grad=True),  torch.tensor(y_test_tensor, dtype=torch.long)\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "\n",
        "    x_train = x_train.cuda()\n",
        "    y_train = y_train.cuda()\n",
        "    x_test  = x_test.cuda()\n",
        "    y_test  = y_test.cuda()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output_train  = model(x_train)\n",
        "    output_test  = model(x_test)\n",
        "\n",
        "    loss_train  = criterion(output_train, y_train)\n",
        "    loss_test = criterion(output_test,  y_test)\n",
        "    train_losses.append(loss_train)\n",
        "    test_losses.append(loss_test)\n",
        "\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "    tr_loss = loss_train.item()\n",
        "\n",
        "    if epoch%2 ==0:\n",
        "      print('Epoch  :', epoch+1, '\\t', 'loss:', loss_test)\n",
        "    "
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "y5btCp-CkbAH",
        "outputId": "a51ab07c-ed2c-4022-e5dc-d645a95ec69b"
      },
      "source": [
        "for epoch in range(n_epoch):\n",
        "  train(epoch)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  : 1 \t loss: tensor(1.9563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Epoch  : 3 \t loss: tensor(1.5039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Epoch  : 5 \t loss: tensor(1.5443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Epoch  : 7 \t loss: tensor(1.4230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Epoch  : 9 \t loss: tensor(1.2261, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-4313f0509215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-130-c598caa0d5fb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtest_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 240.00 MiB (GPU 0; 14.76 GiB total capacity; 12.96 GiB already allocated; 175.75 MiB free; 13.55 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiDUoGCmkn_W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}